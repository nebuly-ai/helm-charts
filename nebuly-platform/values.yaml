backend:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: rootPath: "/backend-service"
  rootPath: ""

  nameOverride: ""
  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-backend
    pullPolicy: IfNotPresent
    tag: "latest"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      memory: 384Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations:
      { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local



frontend:
  nameOverride: ""
  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-frontend
    pullPolicy: IfNotPresent
    tag: "latest"

  # -- The URL of the Backend API to which Frontend will make requests.
  backendApiUrl: ""

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations:
      { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- The full public facing url you use in browser, used for redirects and emails
  rootUrl: ""



eventIngestion:
  # -- Optionally, the base path of the Event Ingestion API when running behind a reverse proxy with a path prefix.
  # -- Example: rootPath: "/event-ingestion"
  rootPath: ""

  nameOverride: ""
  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-event-ingestion
    pullPolicy: IfNotPresent
    tag: "latest"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations:
      { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local



ingestionWorker:
  # -- The number of workers (e.g. coroutines) used to process interactions.
  numWorkersInteractions: 20
  # -- The number of workers (e.g. coroutines) used to process actions.
  numWorkersActions: 10
  # -- The number of workers (e.g. coroutines) used to process feedback actions.
  numWorkersFeedbackActions: 10

  nameOverride: ""
  fullnameOverride: ""

  # -- Settings related to the CronJob for clustering topics.
  topicsClustering:
    # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
    schedule: "@daily"
    resources:
      limits:
        cpu: 1
        memory: 5024Mi
      requests:
        cpu: 1
        memory: 5024Mi

  # -- Settings related to the CronJob for processing the actions of the collected interactions.
  actionsProcessing:
    # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
    schedule: "@daily"
    resources:
      limits:
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 256Mi


  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-ingestion-worker
    pullPolicy: IfNotPresent
    tag: "latest"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    limits:
      memory: 1512Mi
    requests:
      cpu: 500m
      memory: 1024Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }



tenantRegistry:
  # -- The host of the PostgreSQL database used to store service's data.
  postgresServer: ""
  # -- The name of the PostgreSQL database used to store service's data.
  postgresDatabase: "tenant-registry"
  # -- The user for connecting to the database.
  postgresUser: ""
  # -- The password for the database user.
  postgresPassword: ""

  nameOverride: ""
  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-tenant-registry
    pullPolicy: IfNotPresent
    tag: "latest"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    limits:
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }



nameOverride: ""

imagePullSecrets: [ ]
# - name: my-secret-name

secretsStore:
  # -- The kind of Secret Store used to store the secrets.
  # -- Supported values: "database", "azure_keyvault"
  kind: "azure_keyvault"
  # Azure Secret Store configuration. Required only if kind is "azure_keyvault".
  azure:
    # -- The URL of the Azure Key Vault storing the Tenant Registry secrets.
    keyVaultUrl: ""
    # -- The Application ID of the Azure AD application used to access the Azure Key Vault.
    clientId: ""
    # -- The Application Secret of the Azure AD application used to access the Azure Key Vault.
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Key Vault is located.
    tenantId: ""

# -- Optional configuration for the Azure Machine Learning integration.
# -- If provided, a Batch Endpoint on the specified Azure Machine Learning Workspace will be used to
# -- process the collected data.
azureml:
  # -- The client ID (e.g. Application ID) of the Azure AD application used to access the Azure Machine Learning Workspace.
  clientId: ""
  # -- The client secret of the Azure AD application used to access the Azure Machine Learning Workspace.
  clientSecret: ""
  # -- The ID of the Azure Tenant where the Azure Machine Learning Workspace is located.
  tenantId: ""
  # -- The subscription ID of the Azure Machine Learning Workspace.
  subscriptionId: ""
  # -- The name of the Azure resource group containing the Azure Machine Learning Workspace.
  resourceGroup: ""
  # -- The name of the Azure Machine Learning Workspace used to process the collected data.
  workspace: ""
  # -- The name of the Azure Machine Learning Workspace used to process the collected data.
  batchEndpoint: ""


analyticDatabase:
  # -- The host of the database used to store analytic data.
  server: ""
  # -- The name of the database used to store analytic data (interactions, actions, etc.).
  name: "analytics"
  # -- The user for connecting to the database.
  user: ""
  # -- The password for the database user.
  password: ""

kafka:
  # -- Comma separated list of Kafka brokers.
  bootstrapServers: ""
  # -- The username for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # -- when not using an existing secret (see kafka.existingSecret value below).
  saslUsername: ""
  # -- The password for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # -- when not using an existing secret (see kafka.existingSecret value below).
  saslPassword: ""

  # -- Use an existing secret for Kafka authentication.
  existingSecret:
    name: ""
    saslUsernameKey: "username"
    saslPasswordKey: "password"

  # -- If true, the Kafka clients will use the keep alive feature.
  socketKeepAliveEnabled: true
  # -- The name of the main Kafka topic used to store events (e.g. interactions)
  topicEventsMain: "events-main"
  # -- The name of the Kafka topic used to retry events that failed processing.
  topicEventsRetry1: "events-retry-1"
  # -- The name of the Kafka topic used to retry events that failed processing (backoff 2).
  topicEventsRetry2: "events-retry-2"
  # -- The name of the Kafka topic used to retry events that failed processing (backoff 3).
  topicEventsRetry3: "events-retry-3"
  # -- The name of the Kafka topic used as dead letter queue.
  topicEventsDlq: "events-dlq"

otel:
  # -- If True, enable OpenTelemetry instrumentation of the platform services.
  # -- When enables, the services will export traces and metrics in OpenTelemetry format, sending them to the
  # -- OpenTelemetry Collector endpoints specified below.
  enabled: false
  # -- The endpoint of the OpenTelemetry Collector used to collect traces.
  exporterOtlpTracesEndpoint: "http://contrib-collector.otel:4317"
  # -- The endpoint of the OpenTelemetry Collector used to collect metrics.
  exporterOtlpMetricsEndpoint: "http://contrib-collector.otel:4317"

auth:
  # -- If true, an initial admin user with username/password login will be created.
  adminUserEnabled: false
  # -- The username of the initial admin user.
  adminUserUsername: "admin@nebuly.ai"
  # -- The password of the initial admin user.
  adminUserPassword: "admin"


  # -- The OAuth provider used for authentication. Supported values: "microsoft". If empty string,
  # -- only username/password login will be available.
  oauthProvider: "microsoft"

  # -- Microsoft Entra ID authentication configuration. Used when auth.oauthProvider is "microsoft".
  microsoft:
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # -- Microsoft Entra ID application. Must be in the following format:
    # -- "https://<backend-domain>/auth/oauth/microsoft/callback"
    # -- Where <backend-domain> is the domain of the Backend API defined in the backend ingress.
    redirectUri: ""
    # -- The Client ID (e.g. Application ID) of the Microsoft Entra ID application. To be provided only when
    # -- not using an existing secret (see microsoft.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Microsoft Entra ID application. To be provided only when not using an
    # -- existing secret (see microsoft.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Microsoft Entra ID application is located. To be provided only
    # -- when not using an existing secret (see microsoft.existingSecret value below).
    tenantId: ""

    # -- Use an existing secret for Microsoft Entra ID authentication.
    existingSecret:
      name: ""
      clientIdKey: "microsoft-oauth-client-id"
      clientSecretKey: "microsoft-oauth-client-secret"
      tenantIdKey: "microsoft-oauth-tenant-id"


