# -- Override the namespace.
namespaceOverride: ""

# -- Extra annotations that will be added to all resources.
annotations: { }

# -- The name of the service account used by the platform services.
serviceAccount:
  name: "default"
  create: false
  annotations: { }

backend:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy
  # with a path prefix. Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-backend
    pullPolicy: IfNotPresent
    tag: "v1.84.12"

  settings:
    multiTenancyMode: "dynamic_schema"
    # -- The name of the alembic table used to store the status of the backend
    # migrations. If not provided, the default `alembic_version` table will be used.
    alembicTable: ""

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 1024Mi

  scheduler:
    livenessProbe:
      httpGet:
        path: /healthz
        port: http
      initialDelaySeconds: 10
      periodSeconds: 15
      failureThreshold: 10
    readinessProbe:
      httpGet:
        path: /readyz
        port: http
      initialDelaySeconds: 10
      periodSeconds: 10
    resources:
      requests:
        cpu: 100m
      limits:
        memory: 2048Mi

  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- If provided, add a CORS middleware to the auth service with the
  # specified origins.
  #
  # If empty, the CORS middleware will be disabled, and it will be assumed that
  # CORS headers and settings are managed by the Ingress controller.
  corsAllowOrigins: [ ]

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The name of the Sentry environment.
    environment: ""
    # -- The DSN of the Sentry project
    dsn: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

  # -- If interactionsDetailsAccessControlEnabled is true, the roles that are not allowed to access the interactions details.
  interactionsDetailsAccessControlRoles: [ "viewer", "member", "admin" ]

frontend:
  fullnameOverride: ""

  # -- The full public facing url you use in browser, used for redirects.
  rootUrl: ""
  # -- The URL of the Backend API to which Frontend will make requests.
  backendApiUrl: ""
  # -- The URL of the API used for authentication (login, SSO, etc.).
  authApiUrl: ""

  replicaCount: 1

  # -- The default aggregation level of the platform.
  defaultAggregation: "interaction"
  # -- Enable the AB testing feature.
  enableAbTesting: false
  # -- If set to true, enable the AI summarization feature.
  enableAiSummary: false
  # -- Feature flag to activate the old risky behavior page. Used for
  # retro-compatibility.
  enableOldRiskyBehavior: false
  # -- If set to true, enable the sub-categories feature.
  enableSubCategories: false
  # -- If True, hide LLM issues from users without the proper role.
  enableLLMIssueHiding: false
  # -- If True, allow admins to assign/exclude users from organizations.
  enableOrganizationSettings: false
  # -- The relative path to the favicon file.
  faviconPath: "/favicon.svc"
  # -- The title of the application.
  title: "Nebuly"

  customIntentConfig: { }

  image:
    repository: ghcr.io/nebuly-ai/nebuly-frontend
    pullPolicy: IfNotPresent
    tag: "v1.65.10"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    tracesSampleRate: 0
    # -- The sample rate for replay sessions.
    replaySessionSampleRate: 0

eventIngestion:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-event-ingestion
    pullPolicy: IfNotPresent
    tag: "v1.16.1"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 256Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

ingestionWorker:
  # -- The number of workers (e.g. coroutines) used to process interactions.
  numWorkersInteractions: 10
  # -- The number of workers (e.g. coroutines) used to process feedback actions.
  numWorkersFeedbackActions: 10
  # -- The timeout in seconds for the database queries.
  statementTimeoutSeconds: 120

  # -- Additional environment variables, in the standard Kubernetes format.
  # -- Example:
  # - name: MY_ENV_VAR
  #   value: "my-value"
  env: { }

  fullnameOverride: ""

  deploymentStrategy:
    type: Recreate

  # -- Customize the path of the file used for health checks.
  # -- Example: /mnt/health-check/healthy.timestamp
  healthCheckPath: ""

  settings:
    # -- Use the database as a cache for aggregate jobs; disable it for projects with over 1 million interactions.
    enableDbCache: true
    # -- Batch size of entities loaded in each step of aggregate jobs.
    entitiesBatchSize: 20000
    # -- Batch size of interactions loaded in each step of enrich interactions.
    enrichInteractionBatchSize: 10000
    # -- Enable language detection for PII detection.
    enablePiiLanguageDetection: false
    # -- Enable use of LLM (pii-removal) to remove the PII during interaction processing. 
    enablePiiLlm: false
    # -- List of PII keywords to be ignored. You can insert names and addresses that you don't want the PII detection to remove.
    piiDenyList: [ ]
    # -- The name of the alembic table used to store the status of the ingestion worker
    # migrations. If not provided, the default `alembic_version` table will be used.
    alembicTable: ""
    # -- Enable or disable internal worker tasks. This is primarily intended for
    # debugging or performance tuning.
    tasks:
      interaction: true
      traceInteraction: true
      feedbackAction: true
      tags: true


  replicaCount: 1
  image:
    repository: ghcr.io/nebuly-ai/nebuly-ingestion-worker
    pullPolicy: IfNotPresent
    tag: v1.58.9

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
      memory: 1024Mi
    limits:
      cpu: 2
      memory: 2600Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

# -- Settings of the AI models used for inference.
aiModels:
  # -- The kind of registry used to store the AI models. Available values are:
  # "azure_ml", "aws_s3", "azure_storage", "gcp_bucket"
  registry: ""

  modelInferenceInteractions:
    name: "interaction-analyzer-7b-v2"
    version: "28"

  modelTopicClassifier:
    name: "topic-classifier"
    version: "12"

  modelActionClassifier:
    name: "action-classifier"
    version: "6"

  modelLanguageDetection:
    name: "language-detection"
    version: "2"

  modelPiiRemoval:
    name: "pii-removal"
    version: "1"

  # -- Config of the AWS S3 model registry.
  # @default -- -
  aws:
    # -- The name of the AWS S3 bucket.
    bucketName: ""
    # -- Optional AWS S3 endpoint URL. The URL should not include the bucket name.
    # Example: "https://my-domain.com:9444"
    endpointUrl: ""
    # -- Optionally use an existing secret for AWS S3 authentication. If no secret is
    # provided, the services will default to using the Service Account linked to an IAM
    # Role with the required permissions.
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      # -- The key of the secret containing the AWS Access Key ID.
      accessKeyIdKey: ""
      # -- The key of the secret containing the AWS Secret Access Key.
      secretAccessKeyKey: ""

  # -- Config of the GCP Storage model registry.
  # @default -- -
  gcp:
    # -- The name of the GCP bucket.
    bucketName: ""
    # -- The name of the GCP project containing the bucket.
    projectName: ""

  # -- Config of the Azure Storage model registry.
  # @default -- -
  azure:
    # -- The name of the Azure Storage account.
    storageAccountName: ""
    # -- The name of the Azure Storage container.
    storageContainerName: ""
    # -- The tenant ID of the Azure account.
    tenantId: ""
    # -- The client ID of the Azure managed identity used to access the Azure Storage account.
    managedIdentityClientId: ""

  # -- Settings for the Sync Job that pulls AI models from Nebuly's private registry
  # and makes them available in your platform's registry. The Job checks if the
  # specified model versions are available in your private registry. If not, it pulls
  # them from Nebuly's registry and pushes them to your registry.
  # @default -- -
  sync:
    # -- Enable or disable the Sync Job. Default is false for compatibility reasons.
    enabled: false
    # -- The schedule of the job. The format is the same as the Kubernetes CronJob schedule.
    schedule: "0 23 * * *" # Every day at 11:00 PM
    # -- Source Nebuly models registry.
    source:
      clientId: ""
      clientSecret: ""
      # -- Use an existing secret for the AzureML authentication.
      # @default -- -
      existingSecret:
        # -- Name of the secret. Can be templated.
        name: ""
        clientIdKey: ""
        clientSecretKey: ""
    image:
      repository: ghcr.io/nebuly-ai/nebuly-models-sync
      pullPolicy: IfNotPresent
      tag: v0.4.1
    resources:
      requests:
        memory: 4Gi
      limits:
        memory: 8Gi
    securityContext:
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - "ALL"
    podAnnotations: { }
    podLabels: { }
    affinity: { }
    tolerations: [ ]
    nodeSelector: { }
    # -- Additional environment variables, in the standard Kubernetes format.
    # Example:
    # - name: MY_ENV_VAR
    #   value: "my-value"
    env: { }
    podSecurityContext:
      runAsNonRoot: true
    # -- Additional volumes
    volumes: [ ]
    # - name: foo
    #   secret:
    #     secretName: mysecret
    #     optional: false
    # -- Additional volumeMounts
    volumeMounts: [ ]
    # - name: foo
    #   mountPath: "/etc/foo"
    #   readOnly: true

  # -- Config of the Azure Machine Learning model registry.
  # @default -- -
  azureml:
    # -- The client ID of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientId: ""
    # -- The client secret of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Machine Learning Workspace is located.
    # To be provided only when not using an existing secret (see azureml.existingSecret value below).
    tenantId: ""
    # -- The subscription ID of the Azure Machine Learning Workspace.
    subscriptionId: ""
    # -- The name of the Azure resource group containing the Azure Machine Learning Workspace.
    resourceGroup: ""
    # -- The name of the Azure Machine Learning Workspace.
    workspace: ""

    # -- Use an existing secret for the AzureML authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Settings related to the runtime full-processing mode,
# which replaces the primary and secondary processing CronJobs with an always running
# Deployment.
fullProcessing:
  # -- If true, replaces the processing CronJobs with an always
  # running Deployment.
  enabled: false

  settings:
    # -- Seconds of delay between processing.
    processingDelaySeconds: 0

  resources:
    requests:
      cpu: 1
    limits:
      nvidia.com/gpu: 1

  fullnameOverride: ""

  deploymentStrategy:
    type: Recreate

  modelsCache:
    enabled: false
    size: 128Gi
    storageClassName: ""

  podAnnotations: { }
  podLabels: { }

  # -- Additional environment variables, in the standard Kubernetes format.
  # Example:
  # - name: MY_ENV_VAR
  #   value: "my-value"
  env: { }

  # Additional volumes
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false
  # Additional volumeMounts
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  podSecurityContext:
    runAsNonRoot: true
    fsGroup: 101

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"

  # -- Set to True when running on multiple GPUs.
  hostIPC: false

  affinity: { }
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
  nodeSelector: { }

# -- Settings related to the Primary processing CronJobs.
# @default -- -
primaryProcessing:
  # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
  schedule: "0 23 * * *" # Every day at 11:00 PM
  # -- The timezone of the CronJob.
  # If not provided, the default timezone of the Kubernetes cluster will be used.
  timezone: ""
  backoffLimit: 1
  activeDeadlineSeconds: 10800 # 3 hours
  # -- Additional environment variables, in the standard Kubernetes format.
  # Example:
  # - name: MY_ENV_VAR
  #   value: "my-value"
  env: { }
  image:
    repository: ghcr.io/nebuly-ai/nebuly-inference
    pullPolicy: IfNotPresent
    tag: v1.58.9

  # -- Settings of the PVC used to cache AI models.
  modelsCache:
    enabled: false
    size: 128Gi
    storageClassName: ""

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"

  podAnnotations: { }
  podLabels: { }
  podSecurityContext:
    runAsNonRoot: true
    fsGroup: 101

  # Additional volumes
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false
  # Additional volumeMounts
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 1
    limits:
      nvidia.com/gpu: 1

  # -- Set to True when running on multiple GPUs.
  hostIPC: false

  affinity: { }
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
  nodeSelector: { }

imagePullSecrets: [ ]
# - name: my-secret-name

secretsStore:
  # -- The kind of Secret Store used to store the secrets.
  # -- Supported values: "database", "azure_keyvault"
  kind: "database"
  # Azure Secret Store configuration. Required only if kind is "azure_keyvault".
  azure:
    # -- The URL of the Azure Key Vault storing the secrets.
    keyVaultUrl: ""
    # -- The Application ID of the Azure AD application used to access the Azure Key Vault. To be provided only
    # when not using an existing secret (see azure.existingSecret value below).
    clientId: ""
    # -- The Application Secret of the Azure AD application used to access the Azure Key Vault. To be provided
    # only when not using an existing secret (see azure.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Key Vault is located. To be provided only when not using an
    # existing secret (see azure.existingSecret value below).
    tenantId: ""

    # -- Use an existing secret for the Azure Key Vault authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Optional configuration for the OpenAI integration.
# If enabled, the specified models on the OpenAI resource will be used to
# process the collected data.
# Both OpenAI and Azure OpenAI are supported.
# @default -- -
openAi:
  # -- If true, enable the OpenAI integration.
  enabled: true
  # -- For Azure OpenAI: the name of the GPT-4o deployment.
  # For OpenAI: `gpt-4o`.
  gpt4oDeployment: ""
  # -- For Azure OpenAI: the name of the OpenAI Deployment used to translate interactions.
  # For OpenAI: the name of the OpenAI model used to translate interactions.
  translationDeployment: ""
  # -- The endpoint of the OpenAI resource.
  # For Azure OpenAI: `https://<resource-name>.openai.azure.com/`.
  # For OpenAI: `https://api.openai.com/v1`.
  endpoint: ""
  # -- The primary API Key of the OpenAI resource, used for authentication.
  # To be provided only when not using an existing secret (see openAi.existingSecret value below).
  apiKey: ""
  # -- The version of the APIs to use. Used only for Azure OpenAI.
  apiVersion: "2024-02-15-preview"

  # -- Use an existing secret for the Azure OpenAI authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    apiKey: ""

# @default -- -
analyticDatabase:
  # -- The host of the database used to store analytic data.
  server: ""
  # -- The name of the database used to store analytic data (interactions, actions, etc.). To be provided only
  # when not using an existing secret (see analyticDatabase.existingSecret value below).
  name: "analytics"
  # -- The schema of the database used to store analytic data.
  schema: "public"
  # -- The user for connecting to the database.
  user: ""
  # -- The password for the database user. To be provided only when not using an existing secret
  # (see analyticDatabase.existingSecret value below).
  password: ""
  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    userKey: ""
    passwordKey: ""

# @default -- -
kafka:
  # -- If provided, override the default name of the Kafka cluster
  # -- with the provided value.
  nameOverride: ""
  # -- If false, deploy a Kafka cluster together with the platform services. Otherwise,
  # use an existing Kafka cluster.
  external: false
  # -- The name of the user used by the services for connecting to the
  # created kafka cluster.
  user: "nebuly-platform"

  # -- The number of Kafka brokers in the cluster.
  replicas: 3

  affinity: { }

  # -- The storage class used for the Kafka and Zookeeper storage.
  # @default -- -
  storage:
    type: persistent-claim
    size: 10Gi
    deleteClaim: false
    class: default
  rack:
    topologyKey: topology.kubernetes.io/zone
  config:
    replica.selector.class: org.apache.kafka.common.replica.RackAwareReplicaSelector
  #    offsets.topic.replication.factor: 1  -- required if using a single broker

  # Resources of the Kafka brokers.
  # @default -- -
  resources:
    limits:
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 1024Mi
  # Settings of the Zookeeper cluster.
  # @default -- -
  zookeeper:
    replicas: 3
    affinity: { }
    storage:
      type: persistent-claim
      size: 10Gi
      deleteClaim: false
    # Resources of the Zookeeper pods.
    # @default -- -
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 100m
        memory: 1024Mi

  # -- If true, the Kafka clients will use the keep alive feature.
  socketKeepAliveEnabled: true

  # -- Settings of the main Kafka topic used to store events (e.g. interactions)
  topicEventsMain:
    # -- The name of the Kafka topic
    name: "events-main"
    replicas:
    partitions: 8
  # -- Settings f the Kafka topic used to retry events that failed processing.
  topicEventsRetry1:
    # -- The name of the Kafka topic.
    name: "events-retry-1"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 2
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 2).
  topicEventsRetry2:
    # -- The name of the Kafka topic.
    name: "events-retry-2"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 3).
  topicEventsRetry3:
    # -- The name of the Kafka topic.
    name: "events-retry-3"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used as dead letter queue.
  topicEventsDlq:
    # -- The name of the Kafka topic.
    name: "events-dlq"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1

  # -- [external] Comma separated list of Kafka brokers.
  bootstrapServers: ""
  # -- [external] The mechanism used for authentication. Allowed values are:
  # "PLAIN", "GSSAPI", "SCRAM-SHA-512"
  saslMechanism: "PLAIN"
  # -- [external] If True, create the Kafka topics automatically if not present on
  # the specified external Kafka cluster.
  createTopics: true

  # -- [external] The username for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslUsername: ""
  # -- [external] The password for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslPassword: ""

  # -- [external] Used only when saslMechanism is set to "GSSAPI".
  # The service name used for SASL GSSAPI authentication, without the realm.
  # Example: "kafka"
  saslGssapiServiceName: ""
  # -- [external] Used only when saslMechanism is set to "GSSAPI".
  # The principal used for SASL GSSAPI authentication, including the realm.
  # Example: "kafka/kafka.example.com@EXAMPLE.COM"
  saslGssapiKerberosPrincipal: ""
  # -- [external] Used only when saslMechanism is set to "GSSAPI".
  # The Keberos configuration file used for SASL GSSAPI authentication.
  krb5Config: ""

  # -- [external] Use an existing secret for Kafka authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    # -- The key of the secret containing the CA certificate (in PEM format)
    # used for SSL authentication.
    sslCaCertKey: ""
    saslUsernameKey: ""
    saslPasswordKey: ""
    saslGssapiKerberosKeytabKey: ""

# @default -- -
otel:
  # -- If True, enable OpenTelemetry instrumentation of the platform services.
  # When enables, the services will export traces and metrics in OpenTelemetry format, sending them to the
  # OpenTelemetry Collector endpoints specified below.
  enabled: false
  # -- The endpoint of the OpenTelemetry Collector used to collect traces.
  exporterOtlpTracesEndpoint: "http://contrib-collector.otel:4317"
  # -- The endpoint of the OpenTelemetry Collector used to collect metrics.
  exporterOtlpMetricsEndpoint: "http://contrib-collector.otel:4317"

# @default -- -
telemetry:
  # -- If True, enable telemetry collection. Collected telemetry data consists
  # of anonymous usage statistics and error reports.
  enabled: false
  # -- Code of the tenant to which the telemetry data will be associated.
  tenant: ""
  # -- The API key used to authenticate with the telemetry service.
  apiKey: ""
  # -- The Google Tag Manager (GTM) Id.
  gtmId: ""
  # -- If True, enable the Promtail log collector. Only logs from Nebuly's
  # containers will be collected.
  promtail:
    enabled: true

# @default -- -
auth:
  # -- If true, an initial admin user with username/password login will be created.
  adminUserEnabled: false
  # -- The username of the initial admin user.
  adminUserUsername: "admin@nebuly.ai"
  # -- The password of the initial admin user.
  adminUserPassword: "admin"
  # -- The available login modes. Value must be string with the login mode specified
  # as a comma-separated list. Possible values are: `password`, `microsoft`, `okta`,
  # `google`.
  loginModes: "password"
  # -- If True, enable the admin panel for inviting new members to the platform.
  addMembersEnabled: false

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

  # -- Ingress configuration for the login endpoints.
  # @default -- -
  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /auth
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Private RSA Key used for signing JWT tokens. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  jwtSigningKey: ""
  # -- Number of days before a refresh token expires due to inactivity.
  # Determines how long a user can remain logged in without activity before being required to log in again.
  # For example, a value of 1 means users must log in again after 24 hours of inactivity.
  refreshTokenExpirationDays: 7

  # -- The host of the PostgreSQL database used to store user data.
  postgresServer: ""
  # -- The name of the PostgreSQL database used to store user data.
  postgresDatabase: "auth-service"
  # -- The user for connecting to the database. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresUser: ""
  # -- The password for the database user. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresPassword: ""
  # -- The schema of the PostgreSQL database used to store user data.
  postgresSchema: "public"

  # -- If provided, add a CORS middleware to the auth service with the
  # specified origins.
  #
  # If empty, the CORS middleware will be disabled, and it will be assumed that
  # CORS headers and settings are managed by the Ingress controller.
  corsAllowOrigins: [ ]

  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    postgresUserKey: ""
    postgresPasswordKey: ""
    jwtSigningKey: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-tenant-registry
    pullPolicy: IfNotPresent
    tag: "v1.20.11"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      memory: 256Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- LDAP authentication configuration.
  ldap:
    # -- If true, enable LDAP authentication.
    enabled: false
    # -- The address of LDAP server.
    host: ""
    # -- The port of the LDAP server.
    port: "389"
    # -- The LDAP search base to use. Example: `dc=example,dc=org`
    searchBase: ""
    # -- Optional directory root for the LDAP server.
    activeDirectoryRoot: ""
    # -- The search filter to use for user searches.
    # Example: `(&(objectClass=inetOrgPerson))`
    userSearchFilter: ""
    # -- The name of the object class used for groups.
    groupObjectClass: ""
    # -- Mapping between LDAP Roles and Nebuly roles.
    # Example: `<ladp-admin>:admin, <ldap-member>:member, <ldap-viewer>:viewer`.
    roleMapping: ""
    # -- Custom mapping for LDAP attributes used for users full name and email.
    # If not provided, the following attributes will be used:
    # * `mail`: user email
    # * `cn`: user full name
    #
    # When provided, it should be a comma separated list of attributes.
    # Example: `email:<ldap-attribute>,full_name:<ldap-attribute>`
    attributeMapping: ""
    # -- The username of the LDAP user with permissions to perform LDAP searches. To be
    # provided only when not using an existing secret
    # (see auth ldap.existingSecret value below).
    adminUsername: ""
    # -- The password of the LDAP user with permissions to perform LDAP searches. To be
    # provided only when not using an existing secret
    # (see auth ldap.existingSecret value below).
    adminPassword: ""
    existingSecret:
      name: ""
      adminUsernameKey: ""
      adminPasswordKey: ""

  # -- Google authentication configuration. Used when `auth.loginModes` contains "google".
  google:
    enabled: false
    # -- The Client ID of the Google application. To be provided only when not using an existing secret
    # (see google.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Google application. To be provided only when not using an existing secret
    # (see google.existingSecret value below).
    clientSecret: ""
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Okta application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/google/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""
    # -- The mapping between Nebuly roles and Google groups.
    # Example: "viewer:<viewer-group-email>,admin: <admin-group-email>,member: <member-group-email>"
    roleMapping: ""

    # -- Use an existing secret for Google SSO authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

  # -- Okta authentication configuration. Used when `auth.loginModes` contains "okta".
  okta:
    enabled: false
    # -- The Client ID of the Okta application. To be provided only when not using an existing secret
    # (see okta.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Okta application. To be provided only when not using an existing secret
    # (see okta.existingSecret value below).
    clientSecret: ""
    # -- The issuer of the Okta application.
    issuer: ""
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Okta application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/okta/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""

    # -- Use an existing secret for Okta SSO authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

  # -- Microsoft Entra ID authentication configuration. Used when `auth.loginModes`
  # contains "microsoft".
  # @default -- -
  microsoft:
    # -- If true, enable Microsoft Entra ID SSO authentication.
    enabled: false
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Microsoft Entra ID application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/microsoft/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""
    # -- The Client ID (e.g. Application ID) of the Microsoft Entra ID application. To be provided only when
    # not using an existing secret (see microsoft.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Microsoft Entra ID application. To be provided only when not using an
    # existing secret (see microsoft.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Microsoft Entra ID application is located.
    tenantId: ""
    # -- Optional mapping between Nebuly roles and Microsoft Entra ID groups.
    # If not provided, Nebuly roles will be read from the App Roles assigned to users
    # in the Microsoft Entra ID application.
    # Example: "viewer:<group-id>,admin:<group-id>,member:<group-id>"
    roleMapping: ""

    # -- Use an existing secret for Microsoft Entra ID authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Settings for data reprocessing jobs required during major platform upgrades. Keep
# everything disabled by default unless you're upgrading the platform to a major
# release.
reprocessing:
  interactions:
    enabled: false
  modelSuggestions:
    enabled: false
  modelIssues:
    enabled: false
  userIntelligence:
    enabled: false

# -- Post-upgrade hooks settings.
postUpgrade:
  # -- If True, run a post-install jop that runs a full refresh of the backend RO tables.
  refreshRoTables:
    enabled: false
    resources:
      requests:
        cpu: 100m
      limits:
        memory: 512Mi

# -- Optional cert-manager cluster issuer.
# @default --
clusterIssuer:
  enabled: false
  name: letsencrypt
  email: support@nebuly.ai

strimzi:
  enabled: false

clickhouse:
  enabled: false
  # -- Flag to roll out clickhouse progressively on existing postgres
  # installations (first deploy clickhouse, then enable it on backend)
  active: true

  image:
    repository: clickhouse/clickhouse-server
    pullPolicy: IfNotPresent
    tag: "24.12.5-alpine"

  # -- The size of the batches used to ingest data into ClickHouse.
  ingestionBatchSize: 25000

  # -- The name of the ClickHouse database.
  databaseName: analytics

  # -- The number of ClickHouse replicas.
  replicas: 1

  # -- ClickHouse log level.
  logLevel: debug

  # -- Additional volumes on the ClickHouse pods.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # --  Additional volumeMounts on ClickHouse pods.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  affinity: { }
  tolerations: [ ]

  auth:
    # -- Credentials of the user used by Nebuly to access the ClickHouse database.
    nebulyUser:
      username: "nebulyadmin"
      password: "nebuly"
    # -- Credentials of the user used to create backups.
    backupsUser:
      username: "backups"
      password: "nebuly"

  # -- Backups configuration.
  backups:
    # -- If True, enable the backups of the ClickHouse database.
    enabled: false
    restore:
      # -- If True, enable the backup restore cronjob. The cronjob is configured
      # to never run, so it must be manually triggered.
      enabled: false
      # -- The name of the backup to restore.
      # If not provided, the latest backup will be restored.
      backupName: ""
    # -- The settings of the Docker image used to run the backup job.
    image:
      repository: altinity/clickhouse-backup
      pullPolicy: IfNotPresent
      tag: "2.6.5"
    # -- The kind of storage used to store backups.
    # Possible values are: "aws_s3", "gcp_bucket", "azure_storage".
    remoteStorage: ""
    # -- Number of backups to keep locally.
    # Default: keep last day (e.g. last 4 backups).
    numToKeepLocal: 4
    # -- Number of backups to keep on the remote cloud storage.
    # Default: keep last 30 days (e.g. last 120 backups).
    numToKeepRemote: 120
    # -- The schedule of the job. The format is the same as the Kubernetes CronJob schedule.
    # Default: every 4 hours
    schedule: "0 */4 * * *"
    # The day of the week when the full backup is performed (1=Monday, 7=Sunday).
    fullBackupWeekday: 7

    # -- Config of the Azure Storage used for storing backups remotely.
    # @default -- -
    azure:
      # -- The name of the Azure Storage account.
      storageAccountName: ""
      # -- The name of the Azure Storage container.
      storageContainerName: ""
      # -- The storage account key.
      storageAccountKey: ""
      # -- Use an existing secret for the Azure Storage authentication.
      existingSecret:
        # -- Name of the secret. Can be templated.
        name: ""
        # -- The key of the secret containing the Azure Storage Account Key.
        storageAccountKeyKey: ""

    # -- Config of the GCP Storage used for storing backups remotely.
    # @default -- -
    gcp:
      # -- The name of the GCP bucket.
      bucketName: ""
      # -- The name of the GCP project containing the bucket.
      projectName: ""

    # -- Config of the AWS Bucket used for storing backups remotely.
    # @default -- -
    aws:
      # -- The name of the AWS S3 bucket.
      bucketName: ""
      # -- The AWS region where the bucket is located.
      region: ""
      # -- Optional AWS S3 endpoint URL. The URL should not include
      # -- the bucket name. Example: "https://my-domain.com:9444"
      endpointUrl: ""
      # -- Optionally use an existing secret for AWS S3 authentication.
      # -- If no secret is provided, the services will default to using the Service Account
      # -- linked to an IAM Role with the required permissions.
      existingSecret:
        # -- Name of the secret. Can be templated.
        name: ""
        # -- The key of the secret containing the AWS Access Key ID.
        accessKeyIdKey: ""
        # -- The key of the secret containing the AWS Secret Access Key.
        secretAccessKeyKey: ""

  # -- Persistent storage settings.
  storage:
    size: 128Gi
    storageClassName: "default"

  resources:
    requests:
      memory: 13Gi
    limits:
      memory: 13Gi

  keeper:
    enabled: false
    replicas: 1

    # -- The ClickHouse Keeper version to use (Docker image tag).
    image:
      repository: clickhouse/clickhouse-keeper
      pullPolicy: IfNotPresent
      tag: "25.1.5.31"

    resources:
      limits:
        memory: 4Gi

    affinity: { }
    tolerations: [ ]

    # -- Additional volumes on the ClickHouse Keeper pods.
    volumes: [ ]
    # - name: foo
    #   secret:
    #     secretName: mysecret
    #     optional: false

    # --  Additional volumeMounts on ClickHouse Keeper pods.
    volumeMounts: [ ]
    # - name: foo
    #   mountPath: "/etc/foo"
    #   readOnly: true

    # -- Storage configuration of the ClickHouse Keeper instances.
    storage:
      size: 32Gi
      storageClassName: "default"

# -- Settings for controlling the access to the users interactions stored in the
#  platform.
interactionsAccessControl:
  # -- If true, enable the access control for the interactions, making their details
  # available only to the users with the proper roles.
  enabled: false
  # -- Possible values: "disabled", "reason".
  # When set to "reason", the users that are allowed to access the interactions
  # details will need to provide a reason for accessing them.
  openDetailsMode: "disabled"
  # -- The roles that are subject to the open details mode when the access control is
  # enabled.
  #
  # If the openDetailsMode is set to "reason", the users with the specified roles
  # will be able to access the interactions details only if they provide a reason.
  #
  # If the openDetailsMode is set to "disabled", the users with the specified roles
  # won't be able to access the interactions details.
  openDetailsRoles: [ "member", "admin" ]
  # -- The roles for which the input/output fields of the interactions are
  # redacted when the access control is enabled.
  redactedRoles: [ "viewer", "member", "admin" ]

# -- If True, install the Chart `nebuly-ai/bootstrap-aws`, which
# installs all the dependencies required for installing nebuly-platform on
# an EKS cluster on AWS.
bootstrap-aws:
  enabled: false
# -- If True, install the Chart `nebuly-ai/bootstrap-azure`, which
# installs all the dependencies required for installing nebuly-platform on
# an AKS cluster on Microsoft Azure.
bootstrap-azure:
  enabled: false
# -- If True, install the Chart `nebuly-ai/bootstrap-gcp`, which
# installs all the dependencies required for installing nebuly-platform on
# an GKE cluster on Google Cloud Platform.
bootstrap-gcp:
  enabled: false
