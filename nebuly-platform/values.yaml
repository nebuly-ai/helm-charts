# -- Override the namespace.
namespaceOverride: ""

# -- Extra annotations that will be added to all resources.
annotations: { }

# -- The name of the service account used by the platform services.
serviceAccount:
  name: "default"
  create: false
  annotations: { }

backend:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-backend
    pullPolicy: IfNotPresent
    tag: "v1.34.17"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 1024Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The name of the Sentry environment.
    environment: ""
    # -- The DSN of the Sentry project
    dsn: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

frontend:
  fullnameOverride: ""

  # -- The full public facing url you use in browser, used for redirects.
  rootUrl: ""
  # -- The URL of the Backend API to which Frontend will make requests.
  backendApiUrl: ""
  # -- The URL of the API used for authentication (login, SSO, etc.).
  authApiUrl: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-frontend
    pullPolicy: IfNotPresent
    tag: "v1.36.15"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    tracesSampleRate: 0
    # -- The sample rate for replay sessions.
    replaySessionSampleRate: 0

eventIngestion:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-event-ingestion
    pullPolicy: IfNotPresent
    tag: v1.8.1

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 1024Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0


lionLinguist:
  fullnameOverride: ""

  replicaCount: 1

  deploymentStrategy:
    type: Recreate

  # -- The maximum number of concurrent requests that the service will handle.
  maxConcurrentRequests: 8

  # -- Settings of the PVC used to cache AI models.
  modelsCache:
    enabled: true
    size: 64Gi
    storageClassName: ""
    accessModes:
      - ReadWriteMany
      - ReadWriteOnce

  image:
    repository: ghcr.io/nebuly-ai/nebuly-lion-linguist
    pullPolicy: IfNotPresent
    tag: "v0.4.9"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    fsGroup: 101
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 1000m
    limits:
      memory: 6Gi
  nodeSelector: { }

  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists

  affinity: { }

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0


ingestionWorker:
  # -- The number of workers (e.g. coroutines) used to process interactions.
  numWorkersInteractions: 20
  # -- The number of workers (e.g. coroutines) used to process actions.
  numWorkersActions: 10
  # -- The number of workers (e.g. coroutines) used to process feedback actions.
  numWorkersFeedbackActions: 10

  fullnameOverride: ""

  intentVersion: "v1"

  # -- Number o retires that the ingestion worker will attempt when calling
  # -- lion linguist service.
  lionLinguistRetryAttempts: 10

  # -- Thresholds for tuning the data-processing pipeline.
  thresholds:
    subjectClustering: 0.3
    subjectMergeClusters: 0.3
    intentAssignmentToExistingCluster: 0.87
    intentClustering: 0.75
    intentMergeClusters: 0.87

  # -- Settings related to the CronJob for clustering topics.
  # @default -- -
  topicsClustering:
    # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
    schedule: "0 1 * * *" # Every day at 1:00 AM
    resources:
      requests:
        cpu: 1
      limits:
        nvidia.com/gpu: 1
        memory: 8Gi
    tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Exists
    affinity: {}
    nodeSelector: { }

  suggestionsGeneration:
    # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
    schedule: "0 3 * * *" # Every day ad 3:00 AM
    resources:
      requests:
        cpu: 1
      limits:
        nvidia.com/gpu: 1
        memory: 8Gi
    tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Exists
    affinity: { }
    nodeSelector: { }

  replicaCount: 1
  image:
    repository: ghcr.io/nebuly-ai/nebuly-ingestion-worker
    pullPolicy: IfNotPresent
    tag: v1.25.8

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  stage1:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  stage2:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  stage4:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

# -- Settings of the AI models used for inference.
aiModels:
  # -- The kind of registry used to store the AI models.
  # -- Available values are: "azure_ml", "aws_s3", "azure_storage"
  registry: ""

  modelEmbeddingWarnings:
    name: "warning-embedding"
    version: 1

  modelEmbeddingIntents:
    name: "intent-embedding"
    version: 3

  modelEmbeddingTopic:
    name: "topic-embedding"
    version: 4

  modelInferenceInteractions:
    name: "interaction-analyzer-7b-v2"
    version: 12

  # -- Config of the AWS S3 model registry.
  # @default -- -
  aws:
    bucketName: ""

  # -- Config of the Azure Storage model registry.
  # @default -- -
  azure:
    # -- The name of the Azure Storage account.
    storageAccountName: ""
    # -- The name of the Azure Storage container.
    storageContainerName: ""
    # -- The tenant ID of the Azure account.
    tenantId: ""
    # -- The client ID of the Azure managed identity used to access the Azure Storage account.
    managedIdentityClientId: ""

  # -- Settings for the Sync Job that pulls AI models from Nebuly's private registry
  # -- and makes them available in your platform's registry.
  # -- The Job checks if the specified model versions are available in your private
  # -- registry. If not, it pulls them from Nebuly's registry and pushes them
  # -- to your registry.
  # @default -- -
  sync:
    # -- Enable or disable the Sync Job. Default is false for compatibility reasons.
    enabled: false
    # -- The schedule of the job. The format is the same as the Kubernetes CronJob schedule.
    schedule: "0 23 * * *" # Every day at 11:00 PM
    # -- Source Nebuly models registry.
    source:
      clientId: ""
      clientSecret: ""
      # -- Use an existing secret for the AzureML authentication.
      # @default -- -
      existingSecret:
        # -- Name of the secret. Can be templated.
        name: ""
        clientIdKey: ""
        clientSecretKey: ""
    image:
      repository: ghcr.io/nebuly-ai/nebuly-models-sync
      pullPolicy: IfNotPresent
      tag: v0.1.0
    resources:
      requests:
        memory: 4Gi
      limits:
        memory: 8Gi
    securityContext:
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - "ALL"
    podAnnotations: { }
    podLabels: { }
    affinity: { }
    tolerations: [ ]
    nodeSelector: { }
    podSecurityContext:
      runAsNonRoot: true
    # -- Additional volumes
    volumes: [ ]
    # - name: foo
    #   secret:
    #     secretName: mysecret
    #     optional: false
    # -- Additional volumeMounts
    volumeMounts: [ ]
    # - name: foo
    #   mountPath: "/etc/foo"
    #   readOnly: true

  # -- Config of the Azure Machine Learning model registry.
  # @default -- -
  azureml:
    # -- The client ID of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientId: ""
    # -- The client secret of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Machine Learning Workspace is located.
    # To be provided only when not using an existing secret (see azureml.existingSecret value below).
    tenantId: ""
    # -- The subscription ID of the Azure Machine Learning Workspace.
    subscriptionId: ""
    # -- The name of the Azure resource group containing the Azure Machine Learning Workspace.
    resourceGroup: ""
    # -- The name of the Azure Machine Learning Workspace.
    workspace: ""

    # -- Use an existing secret for the AzureML authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""


# -- Settings related to the CronJob for processing the actions of the collected interactions.
# @default -- -
actionsProcessing:
  # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
  schedule: "0 23 * * *" # Every day at 11:00 PM
  backoffLimit: 1
  image:
    repository: ghcr.io/nebuly-ai/nebuly-inference
    pullPolicy: IfNotPresent
    tag: v1.25.8

  # -- Settings of the PVC used to cache AI models.
  modelsCache:
    enabled: false
    size: 64Gi
    storageClassName: ""

  # -- The number of previous hours that the actions processing job will process.
  # -- Example: 24 -> process the last 24 hours of interactions.
  numHoursProcessed: 50

  gpuModel: "A10" # TODO: this we'll be removed soon

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"

  podAnnotations: { }
  podLabels: { }
  podSecurityContext:
    runAsNonRoot: true

  # Additional volumes
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false
  # Additional volumeMounts
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 1
    limits:
      memory: 8Gi
      nvidia.com/gpu: 1

  affinity: { }
  tolerations: [ ]
  nodeSelector: { }

imagePullSecrets: [ ]
# - name: my-secret-name

secretsStore:
  # -- The kind of Secret Store used to store the secrets.
  # -- Supported values: "database", "azure_keyvault"
  kind: "database"
  # Azure Secret Store configuration. Required only if kind is "azure_keyvault".
  azure:
    # -- The URL of the Azure Key Vault storing the secrets.
    keyVaultUrl: ""
    # -- The Application ID of the Azure AD application used to access the Azure Key Vault. To be provided only
    # when not using an existing secret (see azure.existingSecret value below).
    clientId: ""
    # -- The Application Secret of the Azure AD application used to access the Azure Key Vault. To be provided
    # only when not using an existing secret (see azure.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Key Vault is located. To be provided only when not using an
    # existing secret (see azure.existingSecret value below).
    tenantId: ""

    # -- Use an existing secret for the Azure Key Vault authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Optional configuration for the Azure OpenAI integration.
# If enabled, the specified models on the OpenAI resource will be used to
# process the collected data.
# @default -- -
openAi:
  # -- Allowed values: "openai", "azure"
  provider: azure
  # -- If true, enable the OpenAI integration.
  enabled: true
  # -- The name of the OpenAI Deployment used to detect frustration.
  frustrationDetectionDeployment: ""
  # -- The endpoint of the OpenAI resource.
  endpoint: ""
  # -- The primary API Key of the OpenAI resource, used for authentication.
  # To be provided only when not using an existing secret (see openAi.existingSecret value below).
  apiKey: ""
  # -- The version of the APIs to use
  apiVersion: "2024-02-15-preview"

  # -- Use an existing secret for the Azure OpenAI authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    apiKey: ""

# @default -- -
analyticDatabase:
  # -- The host of the database used to store analytic data.
  server: ""
  # -- The name of the database used to store analytic data (interactions, actions, etc.). To be provided only
  # when not using an existing secret (see analyticDatabase.existingSecret value below).
  name: "analytics"
  # -- The user for connecting to the database.
  user: ""
  # -- The password for the database user. To be provided only when not using an existing secret
  # (see analyticDatabase.existingSecret value below).
  password: ""
  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    userKey: ""
    passwordKey: ""

# @default -- -
kafka:
  # -- If true, deploy a Kafka cluster together with the platform services. Otherwise,
  # use an existing Kafka cluster.
  external: false

  # -- The number of Kafka brokers in the cluster.
  replicas: 3

  # -- The storage class used for the Kafka and Zookeeper storage.
  # @default -- -
  storage:
    type: persistent-claim
    size: 10Gi
    deleteClaim: false
    class: default
  rack:
    topologyKey: topology.kubernetes.io/zone
  config:
    replica.selector.class: org.apache.kafka.common.replica.RackAwareReplicaSelector
  #    offsets.topic.replication.factor: 1  -- required if using a single broker

  # Resources of the Kafka brokers.
  # @default -- -
  resources:
    limits:
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 1024Mi
  # Settings of the Zookeeper cluster.
  # @default -- -
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 10Gi
      deleteClaim: false
    # Resources of the Zookeeper pods.
    # @default -- -
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 100m
        memory: 1024Mi

  # -- If true, the Kafka clients will use the keep alive feature.
  socketKeepAliveEnabled: true

  # -- Settings of the main Kafka topic used to store events (e.g. interactions)
  topicEventsMain:
    # -- The name of the Kafka topic
    name: "events-main"
    replicas:
    partitions: 8
  # -- Settings f the Kafka topic used to retry events that failed processing.
  topicEventsRetry1:
    # -- The name of the Kafka topic.
    name: "events-retry-1"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 2
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 2).
  topicEventsRetry2:
    # -- The name of the Kafka topic.
    name: "events-retry-2"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 3).
  topicEventsRetry3:
    # -- The name of the Kafka topic.
    name: "events-retry-3"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used as dead letter queue.
  topicEventsDlq:
    # -- The name of the Kafka topic.
    name: "events-dlq"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1

  # -- [external] Comma separated list of Kafka brokers.
  bootstrapServers: ""
  # -- [external] The username for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslUsername: ""
  # -- [external] The password for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslPassword: ""

  # -- [external] Use an existing secret for Kafka authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    saslUsernameKey: ""
    saslPasswordKey: ""

# @default -- -
otel:
  # -- If True, enable OpenTelemetry instrumentation of the platform services.
  # When enables, the services will export traces and metrics in OpenTelemetry format, sending them to the
  # OpenTelemetry Collector endpoints specified below.
  enabled: false
  # -- The endpoint of the OpenTelemetry Collector used to collect traces.
  exporterOtlpTracesEndpoint: "http://contrib-collector.otel:4317"
  # -- The endpoint of the OpenTelemetry Collector used to collect metrics.
  exporterOtlpMetricsEndpoint: "http://contrib-collector.otel:4317"

# @default -- -
telemetry:
  # -- If True, enable telemetry collection. Collected telemetry data consists
  # of anonymous usage statistics and error reports.
  enabled: false
  # -- The API key used to authenticate with the telemetry service.
  apiKey: ""

# @default -- -
auth:
  # -- If true, an initial admin user with username/password login will be created.
  adminUserEnabled: false
  # -- The username of the initial admin user.
  adminUserUsername: "admin@nebuly.ai"
  # -- The password of the initial admin user.
  adminUserPassword: "admin"
  # -- The available login modes. Value must be string with the login mode specified
  # -- as a comma-separated list. Possible values are: `password`, `microsoft`.
  loginModes: "password"

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

  # -- Ingress configuration for the login endpoints.
  # @default -- -
  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /auth
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Private RSA Key used for signing JWT tokens. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  jwtSigningKey: ""

  # -- The host of the PostgreSQL database used to store user data.
  postgresServer: ""
  # -- The name of the PostgreSQL database used to store user data.
  postgresDatabase: "auth-service"
  # -- The user for connecting to the database. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresUser: ""
  # -- The password for the database user. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresPassword: ""

  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    postgresUserKey: ""
    postgresPasswordKey: ""
    jwtSigningKey: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-tenant-registry
    pullPolicy: IfNotPresent
    tag: "v1.6.10"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      memory: 256Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- Microsoft Entra ID authentication configuration. Used when auth.oauthProvider is "microsoft".
  # @default -- -
  microsoft:
    # -- If true, enable Microsoft Entra ID SSO authentication.
    enabled: false
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Microsoft Entra ID application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/microsoft/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""
    # -- The Client ID (e.g. Application ID) of the Microsoft Entra ID application. To be provided only when
    # not using an existing secret (see microsoft.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Microsoft Entra ID application. To be provided only when not using an
    # existing secret (see microsoft.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Microsoft Entra ID application is located. To be provided only
    # when not using an existing secret (see microsoft.existingSecret value below).
    tenantId: ""

    # -- Use an existing secret for Microsoft Entra ID authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Settings for data reprocessing jobs required during
# -- major platform upgrades.
# -- Keep everything disabled by default unless you're upgrading the platform to a
# -- major release.
reprocessing:
  actions:
    enabled: false
  suggestions:
    enabled: false
  topics:
    enabled: false

# -- Post-upgrade hooks settings.
postUpgrade:
  # -- If True, run a post-install jop that runs a full refresh of the backend RO tables.
  refreshRoTables:
    enabled: false
    resources:
      requests:
        cpu: 100m
      limits:
        memory: 512Mi

# -- Optional cert-manager cluster issuer.
# @default --
clusterIssuer:
  enabled: false
  name: letsencrypt
  email: support@nebuly.ai

strimzi:
  enabled: false

# -- If True, install the Chart `nebuly-ai/bootstrap-aws`, which
# -- installs all the dependencies required for installing nebuly-platform on
# --- an EKS cluster on AWS.
bootstrap-aws:
  enabled: false
# -- If True, install the Chart `nebuly-ai/bootstrap-azure`, which
# -- installs all the dependencies required for installing nebuly-platform on
# --- an AKS cluster on Microsoft Azure.
bootstrap-azure:
  enabled: false