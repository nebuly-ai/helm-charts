# -- Override the namespace.
namespaceOverride: ""

# -- Extra annotations that will be added to all resources.
annotations: { }

# -- The name of the service account used by the platform services.
serviceAccount:
  name: "default"
  create: false
  annotations: { }

backend:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-backend
    pullPolicy: IfNotPresent
    tag: "v1.55.0"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 1024Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- If provided, add a CORS middleware to the auth service with the
  # specified origins.
  #
  # If empty, the CORS middleware will be disabled, and it will be assumed that
  # CORS headers and settings are managed by the Ingress controller.
  corsAllowOrigins: [ ]

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The name of the Sentry environment.
    environment: ""
    # -- The DSN of the Sentry project
    dsn: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

frontend:
  fullnameOverride: ""

  # -- The full public facing url you use in browser, used for redirects.
  rootUrl: ""
  # -- The URL of the Backend API to which Frontend will make requests.
  backendApiUrl: ""
  # -- The URL of the API used for authentication (login, SSO, etc.).
  authApiUrl: ""

  replicaCount: 1

  # -- The default aggregation level of the platform.
  defaultAggregation: "interaction"
  # -- If set to true, enable the AI summarization feature.
  enableAiSummary: false
  # -- Feature flag to activate the old risky behavior page.
  # -- Used for retro-compatibility.
  enableOldRiskyBehavior: false
  enableNewTypeOfRisk: false
  # -- The relative path to the favicon file.
  faviconPath: "/favicon.svc"
  # -- The title of the application.
  title: "Nebuly"

  customIntentConfig: { }

  image:
    repository: ghcr.io/nebuly-ai/nebuly-frontend
    pullPolicy: IfNotPresent
    tag: "v1.50.3"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 128Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    tracesSampleRate: 0
    # -- The sample rate for replay sessions.
    replaySessionSampleRate: 0

eventIngestion:
  # -- Optionally, the base path of the Backend API when running behind a reverse proxy with a path prefix.
  # -- Example: "/backend-service"
  rootPath: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-event-ingestion
    pullPolicy: IfNotPresent
    tag: "v1.9.5"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
    limits:
      memory: 1024Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0


ingestionWorker:
  # -- The number of workers (e.g. coroutines) used to process interactions.
  numWorkersInteractions: 20
  # -- The number of workers (e.g. coroutines) used to process actions.
  numWorkersActions: 10
  # -- The number of workers (e.g. coroutines) used to process feedback actions.
  numWorkersFeedbackActions: 10

  fullnameOverride: ""

  deploymentStrategy:
    type: Recreate

  # -- Customize the path of the file used for health checks.
  # -- Example: /mnt/health-check/healthy.timestamp
  healthCheckPath: ""

  # -- Thresholds for tuning the data-processing pipeline.
  thresholds:
    subjectClustering: 0.3
    subjectMergeClusters: 0.3
    intentClustering: 0.25
    intentMergeClusters: 0.2

  settings:
    topicsAndActionsVersion: v2

  replicaCount: 1
  image:
    repository: ghcr.io/nebuly-ai/nebuly-ingestion-worker
    pullPolicy: IfNotPresent
    tag: v1.42.5

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  stage1:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  stage2:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  stage4:
    resources:
      requests:
        cpu: 100m
        memory: 585Mi
      limits:
        memory: 585Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

# -- Settings of the AI models used for inference.
aiModels:
  # -- The kind of registry used to store the AI models.
  # -- Available values are: "azure_ml", "aws_s3", "azure_storage", "gcp_bucket"
  registry: ""

  modelInferenceInteractions:
    name: "interaction-analyzer-7b-v2"
    version: 18

  modelTopicClassifier:
    name: "topic-classifier"
    version: "6"

  modelActionClassifier:
    name: "action-classifier"
    version: "6"

  # -- Config of the AWS S3 model registry.
  # @default -- -
  aws:
    # -- The name of the AWS S3 bucket.
    bucketName: ""
    # -- Optional AWS S3 endpoint URL. The URL should not include
    # -- the bucket name. Example: "https://my-domain.com:9444"
    endpointUrl: ""
    # -- Optionally use an existing secret for AWS S3 authentication.
    # -- If no secret is provided, the services will default to using the Service Account
    # -- linked to an IAM Role with the required permissions.
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      # -- The key of the secret containing the AWS Access Key ID.
      accessKeyIdKey: ""
      # -- The key of the secret containing the AWS Secret Access Key.
      secretAccessKeyKey: ""

  # -- Config of the AWS S3 model registry.
  # @default -- -
  gcp:
    # -- The name of the GCP bucket.
    bucketName: ""
    # -- The name of the GCP project containing the bucket.
    projectName: ""

  # -- Config of the Azure Storage model registry.
  # @default -- -
  azure:
    # -- The name of the Azure Storage account.
    storageAccountName: ""
    # -- The name of the Azure Storage container.
    storageContainerName: ""
    # -- The tenant ID of the Azure account.
    tenantId: ""
    # -- The client ID of the Azure managed identity used to access the Azure Storage account.
    managedIdentityClientId: ""

  # -- Settings for the Sync Job that pulls AI models from Nebuly's private registry
  # -- and makes them available in your platform's registry.
  # -- The Job checks if the specified model versions are available in your private
  # -- registry. If not, it pulls them from Nebuly's registry and pushes them
  # -- to your registry.
  # @default -- -
  sync:
    # -- Enable or disable the Sync Job. Default is false for compatibility reasons.
    enabled: false
    # -- The schedule of the job. The format is the same as the Kubernetes CronJob schedule.
    schedule: "0 23 * * *" # Every day at 11:00 PM
    # -- Source Nebuly models registry.
    source:
      clientId: ""
      clientSecret: ""
      # -- Use an existing secret for the AzureML authentication.
      # @default -- -
      existingSecret:
        # -- Name of the secret. Can be templated.
        name: ""
        clientIdKey: ""
        clientSecretKey: ""
    image:
      repository: ghcr.io/nebuly-ai/nebuly-models-sync
      pullPolicy: IfNotPresent
      tag: v0.4.1
    resources:
      requests:
        memory: 4Gi
      limits:
        memory: 8Gi
    securityContext:
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop:
          - "ALL"
    podAnnotations: { }
    podLabels: { }
    affinity: { }
    tolerations: [ ]
    nodeSelector: { }
    # -- Additional environment variables, in the standard Kubernetes format.
    # -- Example:
    # - name: MY_ENV_VAR
    #   value: "my-value"
    env: { }
    podSecurityContext:
      runAsNonRoot: true
    # -- Additional volumes
    volumes: [ ]
    # - name: foo
    #   secret:
    #     secretName: mysecret
    #     optional: false
    # -- Additional volumeMounts
    volumeMounts: [ ]
    # - name: foo
    #   mountPath: "/etc/foo"
    #   readOnly: true

  # -- Config of the Azure Machine Learning model registry.
  # @default -- -
  azureml:
    # -- The client ID of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientId: ""
    # -- The client secret of the Azure AD application used to access the Azure Machine Learning Workspace.
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Machine Learning Workspace is located.
    # To be provided only when not using an existing secret (see azureml.existingSecret value below).
    tenantId: ""
    # -- The subscription ID of the Azure Machine Learning Workspace.
    subscriptionId: ""
    # -- The name of the Azure resource group containing the Azure Machine Learning Workspace.
    resourceGroup: ""
    # -- The name of the Azure Machine Learning Workspace.
    workspace: ""

    # -- Use an existing secret for the AzureML authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Settings related to the Primary processing CronJobs.
# @default -- -
primaryProcessing:
  # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
  schedule: "0 23 * * *" # Every day at 11:00 PM
  backoffLimit: 1
  activeDeadlineSeconds: 10800 # 3 hours
  # -- Additional environment variables, in the standard Kubernetes format.
  # -- Example:
  # - name: MY_ENV_VAR
  #   value: "my-value"
  env: { }
  image:
    repository: ghcr.io/nebuly-ai/nebuly-inference
    pullPolicy: IfNotPresent
    tag: v1.42.5
  # -- Settings of the PVC used to cache AI models.
  modelsCache:
    enabled: false
    size: 128Gi
    storageClassName: ""

  # -- The number of previous hours that the actions processing job will process.
  # -- Example: 24 -> process the last 24 hours of interactions.
  numHoursProcessed: 50

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"

  podAnnotations: { }
  podLabels: { }
  podSecurityContext:
    runAsNonRoot: true
    fsGroup: 101

  # Additional volumes
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false
  # Additional volumeMounts
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 1
    limits:
      nvidia.com/gpu: 1

  # -- Set to True when running on multiple GPUs.
  hostIPC: false

  affinity: { }
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
  nodeSelector: { }

# -- Settings related to the Primary processing CronJobs.
# @default -- -
secondaryProcessing:
  # -- The schedule of the CronJob. The format is the same as the Kubernetes CronJob schedule.
  schedule: "0 2 * * *" # Every day at 2:00 AM
  backoffLimit: 1
  activeDeadlineSeconds: 10800 # 3 hours
  resources:
    requests:
      cpu: 1
    limits:
      nvidia.com/gpu: 1

  # -- Additional environment variables, in the standard Kubernetes format.
  # -- Example:
  # - name: MY_ENV_VAR
  #   value: "my-value"
  env: { }

  # -- Settings of the PVC used to cache AI models.
  modelsCache:
    enabled: false
    size: 64Gi
    storageClassName: ""

  modelSuggestions:
    # -- If provided, overrides the schedule of the Model Suggestions CronJob.
    # -- Otherwise, use the schedule specified in `secondaryProcessing.schedule`.
    schedule: ""

  topicsAndActions:
    # -- If provided, overrides the schedule of the Topics and Actions CronJob.
    # -- Otherwise, use the schedule specified in `secondaryProcessing.schedule`.
    schedule: ""

  podAnnotations: { }
  podLabels: { }
  podSecurityContext:
    runAsNonRoot: true
    fsGroup: 101

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"

  # Additional volumes
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false
  # Additional volumeMounts
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  affinity: { }
  tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
  nodeSelector: { }


imagePullSecrets: [ ]
# - name: my-secret-name

secretsStore:
  # -- The kind of Secret Store used to store the secrets.
  # -- Supported values: "database", "azure_keyvault"
  kind: "database"
  # Azure Secret Store configuration. Required only if kind is "azure_keyvault".
  azure:
    # -- The URL of the Azure Key Vault storing the secrets.
    keyVaultUrl: ""
    # -- The Application ID of the Azure AD application used to access the Azure Key Vault. To be provided only
    # when not using an existing secret (see azure.existingSecret value below).
    clientId: ""
    # -- The Application Secret of the Azure AD application used to access the Azure Key Vault. To be provided
    # only when not using an existing secret (see azure.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Azure Key Vault is located. To be provided only when not using an
    # existing secret (see azure.existingSecret value below).
    tenantId: ""

    # -- Use an existing secret for the Azure Key Vault authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Optional configuration for the Azure OpenAI integration.
# If enabled, the specified models on the OpenAI resource will be used to
# process the collected data.
# @default -- -
openAi:
  # -- If true, enable the OpenAI integration.
  enabled: true
  # -- The name of the GPT-4o deployment.
  gpt4oDeployment: ""
  # -- The name of the OpenAI Deployment used to translate interactions.
  translationDeployment: ""
  # -- The endpoint of the OpenAI resource.
  endpoint: ""
  # -- The primary API Key of the OpenAI resource, used for authentication.
  # To be provided only when not using an existing secret (see openAi.existingSecret value below).
  apiKey: ""
  # -- The version of the APIs to use
  apiVersion: "2024-02-15-preview"

  # -- Use an existing secret for the Azure OpenAI authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    apiKey: ""

# @default -- -
analyticDatabase:
  # -- The host of the database used to store analytic data.
  server: ""
  # -- The name of the database used to store analytic data (interactions, actions, etc.). To be provided only
  # when not using an existing secret (see analyticDatabase.existingSecret value below).
  name: "analytics"
  # -- The user for connecting to the database.
  user: ""
  # -- The password for the database user. To be provided only when not using an existing secret
  # (see analyticDatabase.existingSecret value below).
  password: ""
  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    userKey: ""
    passwordKey: ""

# @default -- -
kafka:
  # -- If provided, override the default name of the Kafka cluster
  # -- with the provided value.
  nameOverride: ""
  # -- If true, deploy a Kafka cluster together with the platform services. Otherwise,
  # use an existing Kafka cluster.
  external: false

  # -- The number of Kafka brokers in the cluster.
  replicas: 3

  affinity: { }

  # -- The storage class used for the Kafka and Zookeeper storage.
  # @default -- -
  storage:
    type: persistent-claim
    size: 10Gi
    deleteClaim: false
    class: default
  rack:
    topologyKey: topology.kubernetes.io/zone
  config:
    replica.selector.class: org.apache.kafka.common.replica.RackAwareReplicaSelector
  #    offsets.topic.replication.factor: 1  -- required if using a single broker

  # Resources of the Kafka brokers.
  # @default -- -
  resources:
    limits:
      memory: 2048Mi
    requests:
      cpu: 100m
      memory: 1024Mi
  # Settings of the Zookeeper cluster.
  # @default -- -
  zookeeper:
    replicas: 3
    affinity: { }
    storage:
      type: persistent-claim
      size: 10Gi
      deleteClaim: false
    # Resources of the Zookeeper pods.
    # @default -- -
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 100m
        memory: 1024Mi

  # -- If true, the Kafka clients will use the keep alive feature.
  socketKeepAliveEnabled: true

  # -- Settings of the main Kafka topic used to store events (e.g. interactions)
  topicEventsMain:
    # -- The name of the Kafka topic
    name: "events-main"
    replicas:
    partitions: 8
  # -- Settings f the Kafka topic used to retry events that failed processing.
  topicEventsRetry1:
    # -- The name of the Kafka topic.
    name: "events-retry-1"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 2
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 2).
  topicEventsRetry2:
    # -- The name of the Kafka topic.
    name: "events-retry-2"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used to retry events that failed processing (backoff 3).
  topicEventsRetry3:
    # -- The name of the Kafka topic.
    name: "events-retry-3"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1
  # -- Settings of the Kafka topic used as dead letter queue.
  topicEventsDlq:
    # -- The name of the Kafka topic.
    name: "events-dlq"
    # -- The number of replicas of the Kafka topic. Used only for self-hosted Kafka clusters.
    replicas:
    # -- The number of partitions of the Kafka topic. Used only for self-hosted Kafka clusters.
    partitions: 1

  # -- [external] Comma separated list of Kafka brokers.
  bootstrapServers: ""
  # -- [external] The username for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslUsername: ""
  # -- [external] The password for connecting to the Kafka cluster with the method SASL/PLAIN. To be provided only
  # when not using an existing secret (see kafka.existingSecret value below).
  saslPassword: ""

  # -- [external] Use an existing secret for Kafka authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    saslUsernameKey: ""
    saslPasswordKey: ""

# @default -- -
otel:
  # -- If True, enable OpenTelemetry instrumentation of the platform services.
  # When enables, the services will export traces and metrics in OpenTelemetry format, sending them to the
  # OpenTelemetry Collector endpoints specified below.
  enabled: false
  # -- The endpoint of the OpenTelemetry Collector used to collect traces.
  exporterOtlpTracesEndpoint: "http://contrib-collector.otel:4317"
  # -- The endpoint of the OpenTelemetry Collector used to collect metrics.
  exporterOtlpMetricsEndpoint: "http://contrib-collector.otel:4317"

# @default -- -
telemetry:
  # -- If True, enable telemetry collection. Collected telemetry data consists
  # of anonymous usage statistics and error reports.
  enabled: false
  # -- Code of the tenant to which the telemetry data will be associated.
  tenant: ""
  # -- The API key used to authenticate with the telemetry service.
  apiKey: ""
  # -- If True, enable the Promtail log collector. Only logs from Nebuly's
  # containers will be collected.
  promtail:
    enabled: true

# @default -- -
auth:
  # -- If true, an initial admin user with username/password login will be created.
  adminUserEnabled: false
  # -- The username of the initial admin user.
  adminUserUsername: "admin@nebuly.ai"
  # -- The password of the initial admin user.
  adminUserPassword: "admin"
  # -- The available login modes. Value must be string with the login mode specified
  # -- as a comma-separated list. Possible values are: `password`, `microsoft`, `okta`.
  loginModes: "password"
  # -- If True, enable the admin panel for inviting new members to the platform.
  addMembersEnabled: false

  # -- Settings of the Sentry integration.
  sentry:
    # -- If true, enable the Sentry integration.
    enabled: false
    # -- The DSN of the Sentry project
    dsn: ""
    # -- The name of the Sentry environment.
    environment: ""
    profilesSampleRate: 0
    tracesSampleRate: 0

  # -- Ingress configuration for the login endpoints.
  # @default -- -
  ingress:
    enabled: false
    className: ""
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /auth
            pathType: ImplementationSpecific
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # -- Private RSA Key used for signing JWT tokens. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  jwtSigningKey: ""

  # -- The host of the PostgreSQL database used to store user data.
  postgresServer: ""
  # -- The name of the PostgreSQL database used to store user data.
  postgresDatabase: "auth-service"
  # -- The user for connecting to the database. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresUser: ""
  # -- The password for the database user. Required only if not using an existing secret
  # (see auth.existingSecret value below).
  postgresPassword: ""

  # -- If provided, add a CORS middleware to the auth service with the
  # specified origins.
  #
  # If empty, the CORS middleware will be disabled, and it will be assumed that
  # CORS headers and settings are managed by the Ingress controller.
  corsAllowOrigins: [ ]

  # -- Use an existing secret for the database authentication.
  # @default -- -
  existingSecret:
    # -- Name of the secret. Can be templated.
    name: ""
    postgresUserKey: ""
    postgresPasswordKey: ""
    jwtSigningKey: ""

  fullnameOverride: ""

  replicaCount: 1

  image:
    repository: ghcr.io/nebuly-ai/nebuly-tenant-registry
    pullPolicy: IfNotPresent
    tag: "v1.13.3"

  podAnnotations: { }
  podLabels: { }

  podSecurityContext:
    runAsNonRoot: true

  securityContext:
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - "ALL"
  # readOnlyRootFilesystem: true
  # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  # Additional volumes on the output Deployment definition.
  volumes: [ ]
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # Additional volumeMounts on the output Deployment definition.
  volumeMounts: [ ]
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      memory: 256Mi
  nodeSelector: { }

  tolerations: [ ]

  affinity: { }

  # -- Okta authentication configuration. Used when `auth.loginModes` contains "okta".
  okta:
    enabled: false
    # -- The Client ID of the Okta application. To be provided only when not using an existing secret
    # (see okta.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Okta application. To be provided only when not using an existing secret
    # (see okta.existingSecret value below).
    clientSecret: ""
    # -- The issuer of the Okta application.
    issuer: ""
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Okta application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/microsoft/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""

    # -- Use an existing secret for Okta SSO authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

  # -- Microsoft Entra ID authentication configuration. Used when `auth.loginModes`
  # -- contains "microsoft".
  # @default -- -
  microsoft:
    # -- If true, enable Microsoft Entra ID SSO authentication.
    enabled: false
    # -- The callback URI of the SSO flow. Must be the same as the redirect URI configured for the
    # Microsoft Entra ID application. Must be in the following format:
    # "https://<backend-domain>/auth/oauth/microsoft/callback"
    # Where <backend-domain> is the domain defined in `backend.ingress`.
    redirectUri: ""
    # -- The Client ID (e.g. Application ID) of the Microsoft Entra ID application. To be provided only when
    # not using an existing secret (see microsoft.existingSecret value below).
    clientId: ""
    # -- The Client Secret of the Microsoft Entra ID application. To be provided only when not using an
    # existing secret (see microsoft.existingSecret value below).
    clientSecret: ""
    # -- The ID of the Azure Tenant where the Microsoft Entra ID application is located.
    tenantId: ""

    # -- Use an existing secret for Microsoft Entra ID authentication.
    # @default -- -
    existingSecret:
      # -- Name of the secret. Can be templated.
      name: ""
      clientIdKey: ""
      clientSecretKey: ""

# -- Settings for data reprocessing jobs required during
# -- major platform upgrades.
# -- Keep everything disabled by default unless you're upgrading the platform to a
# -- major release.
reprocessing:
  modelSuggestions:
    enabled: false
  modelIssues:
    enabled: false

# -- Post-upgrade hooks settings.
postUpgrade:
  # -- If True, run a post-install jop that runs a full refresh of the backend RO tables.
  refreshRoTables:
    enabled: false
    resources:
      requests:
        cpu: 100m
      limits:
        memory: 512Mi

# -- Optional cert-manager cluster issuer.
# @default --
clusterIssuer:
  enabled: false
  name: letsencrypt
  email: support@nebuly.ai

strimzi:
  enabled: false

# -- If True, install the Chart `nebuly-ai/bootstrap-aws`, which
# -- installs all the dependencies required for installing nebuly-platform on
# --- an EKS cluster on AWS.
bootstrap-aws:
  enabled: false
# -- If True, install the Chart `nebuly-ai/bootstrap-azure`, which
# -- installs all the dependencies required for installing nebuly-platform on
# --- an AKS cluster on Microsoft Azure.
bootstrap-azure:
  enabled: false
# -- If True, install the Chart `nebuly-ai/bootstrap-gcp`, which
# -- installs all the dependencies required for installing nebuly-platform on
# --- an GKE cluster on Google Cloud Platform.
bootstrap-gcp:
  enabled: false
